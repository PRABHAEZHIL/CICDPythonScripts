{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721dcb52-f040-4b54-ad5f-03bf460ee7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Fetching person profiles...\n",
      "Searching logs for person ID: All from 2025-12-11T00:00:00+08:00 to 2025-12-12T00:00:00+08:00\n",
      "\n",
      "--- Search Results ---\n",
      "‚úÖ Saved Person Authentication IN Record_20251211.csv with 14556 rows\n",
      "‚úÖ Saved Person Authentication IN Record_20251211.csv in C:\\Users\\Bryan.HAU\\Downloads with 14556 rows\n",
      "üìÅ Moved Person Authentication IN Record_20251211.csv to C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\\Person Authentication IN Record_20251211.csv\n",
      "‚úÖ Saved Person Authentication OUT Record_20251211.csv with 11571 rows\n",
      "‚úÖ Saved Person Authentication OUT Record_20251211.csv in C:\\Users\\Bryan.HAU\\Downloads with 11571 rows\n",
      "üìÅ Moved Person Authentication OUT Record_20251211.csv to C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\\Person Authentication OUT Record_20251211.csv\n",
      "‚úÖ Saved Person Authentication IN Record_20251211.csv in C:\\Users\\Bryan.HAU\\Downloads with 14556 rows\n",
      "üìÅ Moved Person Authentication IN Record_20251211.csv to C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\\Person Authentication IN Record_20251211.csv\n",
      "üîê Connecting to SFTP...\n",
      "‚¨Ü Uploading C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\\Person Authentication IN Record_20251211.csv ‚Üí /HikVision/Incoming/Person Authentication IN Record_20251211.csv\n",
      "‚úÖ Upload Complete: Person Authentication IN Record_20251211.csv\n",
      "‚úÖ Saved Person Authentication OUT Record_20251211.csv in C:\\Users\\Bryan.HAU\\Downloads with 11571 rows\n",
      "üìÅ Moved Person Authentication OUT Record_20251211.csv to C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\\Person Authentication OUT Record_20251211.csv\n",
      "üîê Connecting to SFTP...\n",
      "‚¨Ü Uploading C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\\Person Authentication OUT Record_20251211.csv ‚Üí /HikVision/Incoming/Person Authentication OUT Record_20251211.csv\n",
      "‚úÖ Upload Complete: Person Authentication OUT Record_20251211.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import hashlib\n",
    "import hmac\n",
    "import base64\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "import os\n",
    "import shutil\n",
    "from datetime import date, timedelta\n",
    "import paramiko\n",
    "import stat\n",
    "\n",
    "# ==== SFTP connection details ====\n",
    "HOSTNAME = \"SGKOMSFFTAP02\"\n",
    "PORT     = 22\n",
    "USERNAME = \"svc.sftp-isrp\"\n",
    "PASSWORD = \"5$6pL9MRn1$7{T9\"\n",
    "\n",
    "# ==== SFTP Remote Directory ====\n",
    "REMOTE_DIR = \"/HikVision/Incoming/\"\n",
    "\n",
    "\n",
    "def upload_to_sftp(local_file_path):\n",
    "    \"\"\"Uploads a single file to the remote SFTP path\"\"\"\n",
    "    \n",
    "    if not os.path.isfile(local_file_path):\n",
    "        print(f\"‚ö† File not found, skip upload: {local_file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîê Connecting to SFTP...\")\n",
    "    client = paramiko.SSHClient()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    client.connect(\n",
    "        hostname=HOSTNAME,\n",
    "        port=PORT,\n",
    "        username=USERNAME,\n",
    "        password=PASSWORD,\n",
    "        look_for_keys=False,\n",
    "        allow_agent=False\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        sftp = client.open_sftp()\n",
    "        remote_path = os.path.join(REMOTE_DIR, os.path.basename(local_file_path))\n",
    "\n",
    "        print(f\"‚¨Ü Uploading {local_file_path} ‚Üí {remote_path}\")\n",
    "        sftp.put(local_file_path, remote_path)\n",
    "        print(f\"‚úÖ Upload Complete: {os.path.basename(local_file_path)}\")\n",
    "\n",
    "        sftp.close()\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "APP_KEY = \"22793623\"\n",
    "APP_SECRET = \"chi08BQy1ZJioFYc5tz5\"\n",
    "HOST = \"https://118.189.49.19\"\n",
    "\n",
    "# Person ID to Code Mapping\n",
    "person_id_map = {}\n",
    "\n",
    "def create_signature(api_path):\n",
    "    method = \"POST\"\n",
    "    content_type = \"application/json;charset=UTF-8\"\n",
    "    accept = \"application/json\"\n",
    "    string_to_sign = f\"{method}\\n{accept}\\n{content_type}\\n{api_path}\"\n",
    "    return base64.b64encode(\n",
    "        hmac.new(APP_SECRET.encode(), string_to_sign.encode(), hashlib.sha256).digest()\n",
    "    )\n",
    "\n",
    "def call_hik_api(api_path, payload, headers_override=None):\n",
    "    url = HOST + api_path\n",
    "    timestamp = str(int(time.time()))\n",
    "    signature = create_signature(api_path)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json;charset=UTF-8\",\n",
    "        \"userId\": \"admin\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"X-Ca-Key\": APP_KEY,\n",
    "        \"X-Ca-Signature\": signature,\n",
    "        \"X-Ca-Timestamp\": timestamp\n",
    "    }\n",
    "    if headers_override:\n",
    "        headers.update(headers_override)\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, verify=False)\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå API error:\", e)\n",
    "        return {}\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "APP_KEY = \"22793623\"\n",
    "APP_SECRET = \"chi08BQy1ZJioFYc5tz5\"\n",
    "HOST = \"https://118.189.49.19\"\n",
    "\n",
    "# Person ID to Code Mapping\n",
    "person_id_map = {} # Initialize as a dictionary\n",
    "\n",
    "#use 2 line below for yesterday\n",
    "start = f\"{(date.today() - timedelta(days=1))}T00:00:00+08:00\"\n",
    "end = f\"{date.today()}T00:00:00+08:00\"\n",
    "\n",
    "\n",
    "# # use 2 line below for the day itself\n",
    "# start = f\"{date.today()}T00:00:00+08:00\"\n",
    "# end = f\"{date.today()}T23:59:00+08:00\"\n",
    "\n",
    "def create_signature(api_path):\n",
    "    method = \"POST\"\n",
    "    content_type = \"application/json;charset=UTF-8\"\n",
    "    accept = \"application/json\"\n",
    "    string_to_sign = f\"{method}\\n{accept}\\n{content_type}\\n{api_path}\"\n",
    "    return base64.b64encode(\n",
    "        hmac.new(APP_SECRET.encode(), string_to_sign.encode(), hashlib.sha256).digest()\n",
    "    ).decode()\n",
    "\n",
    "def call_hik_api(api_path, payload, headers_override=None):\n",
    "    url = HOST + api_path\n",
    "    timestamp = str(int(time.time()))\n",
    "    signature = create_signature(api_path)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json;charset=UTF-8\",\n",
    "        \"userId\": \"admin\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"X-Ca-Key\": APP_KEY,\n",
    "        \"X-Ca-Signature\": signature,\n",
    "        \"X-Ca-Timestamp\": timestamp\n",
    "    }\n",
    "    if headers_override:\n",
    "        headers.update(headers_override)\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, verify=False)\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå API error:\", e)\n",
    "        return {}\n",
    "\n",
    "def fetch_person_profiles():\n",
    "    global person_id_map\n",
    "    page = 1\n",
    "    while True:\n",
    "        payload = {\"pageNo\": page, \"pageSize\": 500, \"appendInfo\": [6]}\n",
    "        data = call_hik_api(\"/artemis/api/resource/v1/person/personList\", payload)\n",
    "        if not isinstance(data, dict):\n",
    "            print(\"‚ùå Invalid personList response (not JSON):\", data)\n",
    "            break\n",
    "        records = data.get(\"data\", {}).get(\"list\", [])\n",
    "        if not records:\n",
    "            break\n",
    "        for rec in records:\n",
    "            pid = rec.get(\"personId\")\n",
    "            pcode = rec.get(\"personCode\")\n",
    "            if pid and pcode:\n",
    "                person_id_map[pid] = pcode\n",
    "        page += 1\n",
    "\n",
    "def get_fr_terminal_logs(start, end, person_id=None):\n",
    "    CLOCKING_DOOR_IDS = [\"2996\", \"2997\", \"3727\", \"3263\", \"3468\", \"3470\", # 4 TBY (3 IN, 1 OUT) & 2 AY LODGE\n",
    "                         \"3682\", \"3677\", \"3692\", \"3687\", \"3078\", \"3118\", \"3123\", \"3083\", \"3088\", \"3699\", \"3642\", \"3637\", \"3000\",\n",
    "                         \"3704\", \"3010\", \"2987\", \"2985\", \"2992\", \"3632\", \"2998\", \"3732\", \"3709\", \"3015\", \"3024\", \"3652\", \"3647\",\n",
    "                         \"3005\", \"3220\", \"3828\", \"3230\", \"3235\", \"3271\", \"3190\", \"3276\", \"3195\", \"3200\", \"3205\", \"3210\", \"3215\",\n",
    "                         \"3055\", \"2810\", \"3258\"] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def get_fr_terminal_logs(start, end, person_id=None):\n",
    "#     CLOCKING_DOOR_IDS = [\"83\", \"199\", \"290\", \"310\", \"315\", \"320\", \"325\", \"330\", \"335\", \"340\",\n",
    "#                             \"1709\", \"1841\", \"1842\", \"1843\", \"1892\", \"1893\",\n",
    "#                             \"2062\", \"2173\", \"2179\", \"2185\", \"2214\", \"2219\", \"2224\", \"2229\", \"2239\",\n",
    "#                             \"2265\", \"2270\", \"2275\", \"2280\", \"2285\", \"2295\", \"2315\", \"2320\", \"2325\",\n",
    "#                             \"2330\", \"2332\", \"2334\", \"2337\", \"2342\", \"2347\", \"2352\", \"2357\",\n",
    "#                             \"2490\", \"2492\", \"2576\", \"2590\", \"2593\", \"2606\",\n",
    "#                             \"2638\", \"2642\", \"2643\", \"2644\", \"2645\", \"2646\",\n",
    "#                             \"2660\", \"2661\", \"2662\", \"2663\", \"2664\", \"2665\", \"2666\", \"2667\", \"2669\", \"2671\",\n",
    "#                             \"2796\", \"2797\", \"2798\", \"2799\", \"2800\", \"2801\", \"2802\", \"2803\", \"2804\", \"2805\", \"2810\",\n",
    "#                             \"2985\", \"2987\", \"2992\", \"2996\", \"2997\", \"2998\", \"3000\", \"3005\", \"3010\", \"3015\", \"3024\", \"3055\",\n",
    "#                             \"3078\", \"3083\", \"3088\", \"3093\", \"3098\", \"3103\", \"3108\", \"3113\", \"3118\", \"3123\",\n",
    "#                             \"3190\", \"3195\", \"3200\", \"3205\", \"3210\", \"3215\", \"3220\", \"3225\", \"3230\", \"3235\",\n",
    "#                             \"3258\", \"3263\", \"3699\", \"3642\", \"3637\", \"3000\", \"3704\", \"2987\",\n",
    "#                             \"3632\", \"3709\", \"3652\", \"3647\", \"3271\", \"3276\", \"3470\" , \"3468\"]  # Office IDs now included\n",
    "\n",
    "\n",
    "    #recently added on 11/11:\n",
    "\n",
    "# 3699\t3642\t3637\t3000\t3704\t2987\t3632\t3709\t3652\t3647\t3271\t3276\n",
    "    logs = []\n",
    "    for i in range(0, len(CLOCKING_DOOR_IDS), 10):\n",
    "        batch = CLOCKING_DOOR_IDS[i:i + 10]\n",
    "        page = 1\n",
    "        while True:\n",
    "            payload = {\n",
    "                \"startTime\": start,\n",
    "                \"endTime\": end,\n",
    "                \"eventType\": 196893,\n",
    "                \"doorIndexCodes\": batch,\n",
    "                \"pageNo\": page,\n",
    "                \"pageSize\": 100\n",
    "            }\n",
    "            if person_id:\n",
    "                payload[\"certificateNo\"] = person_id\n",
    "            data = call_hik_api(\"/artemis/api/acs/v1/door/events\", payload)\n",
    "            records = data.get(\"data\", {}).get(\"list\", [])\n",
    "            if not records:\n",
    "                break\n",
    "            for rec in records:\n",
    "                door_id = rec.get(\"doorIndexCode\", \"\")\n",
    "                logs.append({\n",
    "                    \"Name\": rec.get(\"personName\", \"\"),\n",
    "                    \"ID\": person_id_map.get(rec.get(\"personId\", \"\"), rec.get(\"personId\", \"\")),\n",
    "                    \"Door\": door_id,\n",
    "                    \"Time\": rec.get(\"eventTime\", \"\"),\n",
    "                    \"Device\": rec.get(\"doorName\", \"\")\n",
    "                })\n",
    "            page += 1\n",
    "    return logs\n",
    "\n",
    "\n",
    "# --- Modified run_search function ---\n",
    "def run_search(start_time, end_time, person_id=None):\n",
    "    logs = []\n",
    "    print(f\"Searching logs for person ID: {person_id or 'All'} from {start_time} to {end_time}\")\n",
    "\n",
    "    logs.extend(get_fr_terminal_logs(start_time, end_time))\n",
    "\n",
    "    if person_id:\n",
    "        logs = [log for log in logs if log.get(\"ID\") == person_id == person_id] # Added Plate for ANPR filtering\n",
    "\n",
    "    logs.sort(key=lambda x: x[\"Time\"])\n",
    "    return logs # Return the logs instead of updating a global variable for display\n",
    "\n",
    "# --- Execution ---\n",
    "print(\"üì° Fetching person profiles...\")\n",
    "fetch_person_profiles()\n",
    "\n",
    "# If you want to search for a specific person ID, pass it here\n",
    "# For example: search_results = run_search(start, end, person_id=\"1001985\")\n",
    "search_results = run_search(start, end) # Calling without a specific person_id to get all logs\n",
    "#search_results = run_search(start, end, person_id = \"1001985\")\n",
    "\n",
    "print(\"\\n--- Search Results ---\")\n",
    "if search_results:\n",
    "    # Convert list of dictionaries to a Pandas DataFrame\n",
    "    df = pd.DataFrame(search_results)\n",
    "\n",
    "    # Define the output Excel file name\n",
    "    output_filename = \"hikvision_logs.xlsx\"\n",
    "    df = df.rename(columns={'Name': 'First Name', 'ID': 'Person No.','Device': 'Access Point'})\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    df['Time'] = df['Time'].dt.tz_localize(None)\n",
    "    # Output folder\n",
    "    output_folder = r\"C:\\Users\\Bryan.HAU\\Downloads\"\n",
    "    # Create a \"Date\" column to group by day\n",
    "    df['Date'] = df['Time'].dt.date\n",
    "    # Loop through each unique date and save a separate Excel file\n",
    "    df.drop(['Door'], axis=1, inplace = True)\n",
    "    # df = df[df['Access Point'].str.contains('TBY', case=False, na=False)]\n",
    "    df[df['Access Point'].str.contains('TBY', case=False, na=False) | df['Access Point'].str.contains('AY ALAUNIA LODGE iSRP', case=False, na=False)]\n",
    "    # Loop through each unique date\n",
    "    for day, group in df.groupby('Date'):\n",
    "        # Format date as ddMMyyyy\n",
    "        date_str = pd.to_datetime(day).strftime(\"%Y%m%d\")\n",
    "    \n",
    "        # --- Split into IN and OUT ---\n",
    "        df_in = group[group['Access Point'].str.contains(\"IN\", case=False, na=False)]\n",
    "        df_out = group[group['Access Point'].str.contains(\"OUT\", case=False, na=False)]\n",
    "\n",
    "        output_folder = r\"C:\\Users\\Bryan.HAU\\Downloads\"\n",
    "        destination_folder = r\"C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\"\n",
    "    \n",
    "        # Save IN file if not empty\n",
    "        if not df_in.empty:\n",
    "            output_filename_in = f\"Person Authentication IN Record_{date_str}.csv\"\n",
    "            output_path_in = os.path.join(output_folder, output_filename_in)\n",
    "            df_in.drop(columns=['Date']).sort_values(by='Time').to_csv(output_path_in, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Saved {output_filename_in} with {len(df_in)} rows\")\n",
    "\n",
    "             # Save file in Downloads\n",
    "            df_in.drop(columns=['Date']).sort_values(by='Time').to_csv(output_path_in, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Saved {output_filename_in} in {output_folder} with {len(df_in)} rows\")\n",
    "\n",
    "             # Move file to OneDrive Testing folder\n",
    "            final_path_in = os.path.join(destination_folder, output_filename_in)\n",
    "            shutil.move(output_path_in, final_path_in)\n",
    "            print(f\"üìÅ Moved {output_filename_in} to {final_path_in}\")\n",
    "\n",
    "    \n",
    "        # Save OUT file if not empty\n",
    "        if not df_out.empty:\n",
    "            output_filename_out = f\"Person Authentication OUT Record_{date_str}.csv\"\n",
    "            output_path_out = os.path.join(output_folder, output_filename_out)\n",
    "            df_out.drop(columns=['Date']).sort_values(by='Time').to_csv(output_path_out, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Saved {output_filename_out} with {len(df_out)} rows\")\n",
    "\n",
    "              # Save file in Downloads\n",
    "            df_out.drop(columns=['Date']).sort_values(by='Time').to_csv(output_path_out, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Saved {output_filename_out} in {output_folder} with {len(df_out)} rows\")\n",
    "\n",
    "             # Move file to OneDrive Testing folder\n",
    "            final_path_out = os.path.join(destination_folder, output_filename_out)\n",
    "            shutil.move(output_path_out, final_path_out)\n",
    "            print(f\"üìÅ Moved {output_filename_out} to {final_path_out}\")\n",
    "\n",
    "\n",
    "            df_in = group[group['Access Point'].str.contains(\"IN\", case=False, na=False)]\n",
    "            df_out = group[group['Access Point'].str.contains(\"OUT\", case=False, na=False)]\n",
    "\n",
    "            output_folder = r\"C:\\Users\\Bryan.HAU\\Downloads\"\n",
    "            destination_folder = r\"C:\\Users\\Bryan.HAU\\Service4 OneDrive\\OneDrive - Seatrium Ltd\\Digital Trace\\TBY FR reports\"\n",
    "\n",
    "            # --------------------------\n",
    "            # Process IN File\n",
    "            # --------------------------\n",
    "            if not df_in.empty:\n",
    "                output_filename_in = f\"Person Authentication IN Record_{date_str}.csv\"\n",
    "                output_path_in = os.path.join(output_folder, output_filename_in)\n",
    "                df_in.drop(columns=['Date']).sort_values(by='Time').to_csv(output_path_in, index=False, encoding=\"utf-8-sig\")\n",
    "                print(f\"‚úÖ Saved {output_filename_in} in {output_folder} with {len(df_in)} rows\")\n",
    "            \n",
    "                # Move to OneDrive\n",
    "                final_path_in = os.path.join(destination_folder, output_filename_in)\n",
    "                shutil.move(output_path_in, final_path_in)\n",
    "                print(f\"üìÅ Moved {output_filename_in} to {final_path_in}\")\n",
    "            \n",
    "                # Upload to SFTP\n",
    "                upload_to_sftp(final_path_in)\n",
    "\n",
    "\n",
    "            # --------------------------\n",
    "            # Process OUT File\n",
    "            # --------------------------\n",
    "            if not df_out.empty:\n",
    "                output_filename_out = f\"Person Authentication OUT Record_{date_str}.csv\"\n",
    "                output_path_out = os.path.join(output_folder, output_filename_out)\n",
    "                df_out.drop(columns=['Date']).sort_values(by='Time').to_csv(output_path_out, index=False, encoding=\"utf-8-sig\")\n",
    "                print(f\"‚úÖ Saved {output_filename_out} in {output_folder} with {len(df_out)} rows\")\n",
    "            \n",
    "                # Move to OneDrive\n",
    "                final_path_out = os.path.join(destination_folder, output_filename_out)\n",
    "                shutil.move(output_path_out, final_path_out)\n",
    "                print(f\"üìÅ Moved {output_filename_out} to {final_path_out}\")\n",
    "            \n",
    "                # Upload to SFTP\n",
    "                upload_to_sftp(final_path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9e2b2-5d9b-495f-ae8a-572849ca5cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
